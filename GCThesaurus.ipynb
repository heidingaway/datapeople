{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg2F/dSpR8FjzvzsER6181",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heidingaway/datapeople/blob/main/GCThesaurus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import yaml\n",
        "import re\n",
        "import unicodedata\n",
        "import hashlib\n",
        "from pickle import DEFAULT_PROTOCOL\n",
        "\n",
        "def to_lower_camel_case(text):\n",
        "    # Remove any leading/trailing spaces or underscores\n",
        "    text = text.strip().strip('_')\n",
        "    # Split the text into words based on underscores\n",
        "    words = text.split('_')\n",
        "    # Convert the first word to lowercase and the rest to title case, then join them\n",
        "    camel_case = words[0].lower() + ''.join(word.title() for word in words[1:])\n",
        "    return camel_case"
      ],
      "metadata": {
        "id": "R3eMDEo0AGB1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6o7v1_-E_9Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201f8302-63cd-4cf9-ce14-1ef3399c636d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               subject predicate           longTitle identifier\n",
            "1475         Art works    french         Œuvre d'art       1475\n",
            "10161     Human beings    french         Être humain      10161\n",
            "19251    Sports events    french   Événement sportif      19251\n",
            "4635   Cultural events    french  Événement culturel       4635\n",
            "19712    Tax avoidance    french    Évitement fiscal      19712\n",
            "subject       22146\n",
            "predicate     22146\n",
            "longTitle     22146\n",
            "identifier    22146\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Link to CSV\n",
        "\n",
        "src = \"https://canada.multites.net/cst/EAEAD1E6-7DD2-4997-BE7F-40BFB1CBE8A2/CST20240911.csv\"\n",
        "\n",
        "# Create the DataFrame from all the retrieved records\n",
        "df = pd.read_csv(src)\n",
        "\n",
        "# Add column names\n",
        "df.columns = ['subject', 'predicate', 'object']\n",
        "\n",
        "# Create a new column 'identifier' using the index number\n",
        "df['identifier'] = df.index.astype(str) # Use index as identifier\n",
        "\n",
        "# identify long title\n",
        "df = df.rename(columns={'object': 'longTitle'}).sort_values(by='longTitle', ascending=False)\n",
        "\n",
        "#lowercamelcase\n",
        "df['predicate'] = df['predicate'].apply(to_lower_camel_case)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove accents and special characters from a string\n",
        "def clean_title(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii') # Remove accents\n",
        "    text = re.sub(r\"[^a-zA-Z0-9 -]\", \"\", text)  # Remove special characters except spaces and dashes\n",
        "    text = text[:50]  # Truncate to 50 characters if longer\n",
        "    return text\n",
        "\n",
        "# Group by 'longTitle' and 'predicate' and aggregate 'linkedsubject' with comma separation\n",
        "grouped_df = df.groupby(['longTitle', 'predicate'])['subject'].apply(lambda x: ', '.join(x)).reset_index()\n",
        "\n",
        "# Define the strings you want to add\n",
        "prefix = \"\\\"[[\"  # Prefix without identifier\n",
        "suffix = \"]]\\\"\"\n",
        "\n",
        "grouped_df['subject'] = grouped_df['subject'].apply(clean_title)\n",
        "grouped_df['subject'] = grouped_df.apply(lambda row: f\"{prefix}{row['subject']}{suffix}\", axis=1)\n",
        "\n",
        "# Before pivoting, reset the index and make \"identifier\" a column instead of the index.\n",
        "pivoted_df = grouped_df.pivot_table(\n",
        "    index='longTitle',\n",
        "    columns='predicate',\n",
        "    values='subject',\n",
        "    aggfunc=lambda x: ', '.join(x.dropna().astype(str)) # Changed aggfunc to join values\n",
        ")\n",
        "\n",
        "# Reset index to make 'title' a column again\n",
        "pivoted_df = pivoted_df.reset_index()\n",
        "\n",
        "\n",
        "# Apply cleaning function to the 'title' and 'subject' column\n",
        "pivoted_df['title'] = pivoted_df['longTitle'].apply(clean_title)\n",
        "pivoted_df['longTitle'] = \"'\" + pivoted_df['longTitle'] + \"'\"\n",
        "\n",
        "for column in pivoted_df.columns:\n",
        "    if column not in ['title', 'longTitle']:\n",
        "        pivoted_df[column] = pivoted_df[column].str.replace(\"], \", \"\\n- \", regex=False)\n",
        "\n",
        "# Apply cleaning function to the 'title' and 'subject' column\n",
        "\n",
        "print(pivoted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdrT1pwue4f_",
        "outputId": "66d28d3a-29e9-4f40-a0dc-1e5594806e53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicate                                          longTitle broader term  \\\n",
            "0          '\"Bicycle paths\" replaces \"Cycling trails\" as ...          NaN   \n",
            "1          '\"Biochemicals\" replaces \"Biochemical products...          NaN   \n",
            "2          '\"Coasts\" replaces \"Coastlands\" as preferred t...          NaN   \n",
            "3          '\"Cultural groups\" replaces \"Cultural minoriti...          NaN   \n",
            "4          '\"Demining\" replaces \"Mine clearing\" as prefer...          NaN   \n",
            "...                                                      ...          ...   \n",
            "7583                                      'Évitement fiscal'          NaN   \n",
            "7584                                    'Événement culturel'          NaN   \n",
            "7585                                     'Événement sportif'          NaN   \n",
            "7586                                           'Être humain'          NaN   \n",
            "7587                                           'Œuvre d'art'          NaN   \n",
            "\n",
            "predicate                 french                               history note  \\\n",
            "0                            NaN         \"[[Cycling trails Bicycle paths]]\"   \n",
            "1                            NaN    \"[[Biochemicals Biochemical products]]\"   \n",
            "2                            NaN                    \"[[Coastlands Coasts]]\"   \n",
            "3                            NaN  \"[[Cultural groups Cultural minorities]]\"   \n",
            "4                            NaN               \"[[Demining Mine clearing]]\"   \n",
            "...                          ...                                        ...   \n",
            "7583         \"[[Tax avoidance]]\"                                        NaN   \n",
            "7584       \"[[Cultural events]]\"                                        NaN   \n",
            "7585         \"[[Sports events]]\"                                        NaN   \n",
            "7586          \"[[Human beings]]\"                                        NaN   \n",
            "7587             \"[[Art works]]\"                                        NaN   \n",
            "\n",
            "predicate narrower term related term scope note subject category  use  \\\n",
            "0                   NaN          NaN        NaN              NaN  NaN   \n",
            "1                   NaN          NaN        NaN              NaN  NaN   \n",
            "2                   NaN          NaN        NaN              NaN  NaN   \n",
            "3                   NaN          NaN        NaN              NaN  NaN   \n",
            "4                   NaN          NaN        NaN              NaN  NaN   \n",
            "...                 ...          ...        ...              ...  ...   \n",
            "7583                NaN          NaN        NaN              NaN  NaN   \n",
            "7584                NaN          NaN        NaN              NaN  NaN   \n",
            "7585                NaN          NaN        NaN              NaN  NaN   \n",
            "7586                NaN          NaN        NaN              NaN  NaN   \n",
            "7587                NaN          NaN        NaN              NaN  NaN   \n",
            "\n",
            "predicate used for                                              title  \n",
            "0              NaN  Bicycle paths replaces Cycling trails as prefe...  \n",
            "1              NaN  Biochemicals replaces Biochemical products as ...  \n",
            "2              NaN  Coasts replaces Coastlands as preferred term i...  \n",
            "3              NaN  Cultural groups replaces Cultural minorities a...  \n",
            "4              NaN  Demining replaces Mine clearing as preferred t...  \n",
            "...            ...                                                ...  \n",
            "7583           NaN                                   Evitement fiscal  \n",
            "7584           NaN                                 Evenement culturel  \n",
            "7585           NaN                                  Evenement sportif  \n",
            "7586           NaN                                        Etre humain  \n",
            "7587           NaN                                          uvre dart  \n",
            "\n",
            "[7588 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"csv_files\"\n",
        "i = 1\n",
        "while os.path.exists(output_dir):\n",
        "    output_dir = f\"csv_files_{i}\"\n",
        "    i += 1\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "# Iterate through each group (title) and export to CSV\n",
        "for title, group_data in pivoted_df.groupby('title'):\n",
        "    file_name = f\"{title}.csv\"  #\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "    group_data.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"CSV files exported to: {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TjdNFdce9iQ",
        "outputId": "02de0587-7f79-44e5-9950-b5b0845cede3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files exported to: csv_files_4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for Markdown files with a unique name\n",
        "dir_name = \"markdown_files\"\n",
        "i = 1\n",
        "while os.path.exists(dir_name):\n",
        "    dir_name = f\"markdown_files_{i}\"\n",
        "    i += 1\n",
        "os.makedirs(dir_name)\n",
        "\n",
        "# Function to create markdown content with bullet points\n",
        "def create_markdown_content(row):\n",
        "    markdown_content = f\"---\\ntitle: {row['title']}\\ntags:\\n- gccommon\\n\"\n",
        "    for column in pivoted_df.columns:\n",
        "        if column not in ['title', 'longTitle'] and pd.notna(row[column]) and row[column] != '':\n",
        "            markdown_content += f\"{column}\\n\"  # Heading for the section\n",
        "            markdown_content += f\"- {row[column]}\\n\"  # Add the bulleted content\n",
        "    markdown_content += \"---\"\n",
        "    return markdown_content\n",
        "\n",
        "# Create the markdown files\n",
        "def create_markdown_file(row):  # Define a function to create individual files\n",
        "    file_name = os.path.join(dir_name, f\"{row['title']}.md\")\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(create_markdown_content(row))\n",
        "\n",
        "pivoted_df.apply(create_markdown_file, axis=1)  # Apply to pivoted_df\n",
        "\n",
        "print(f\"Markdown files created successfully in directory: {dir_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pewv8_KkqoQ",
        "outputId": "d0593e91-b80f-46e2-d36a-79276083a914"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markdown files created successfully in directory: markdown_files_4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file of the markdown directory\n",
        "def zip_directory(directory_path, zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "        for root, _, files in os.walk(directory_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, directory_path)\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "# Zip the 'markdown_files' directory\n",
        "zip_directory(dir_name, 'markdown_files.zip')\n",
        "\n",
        "print(f\"Markdown files zipped to: markdown_files.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUiOPOWInkWU",
        "outputId": "f5079b6a-100b-41aa-e378-456c3ba27717"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markdown files zipped to: markdown_files.zip\n"
          ]
        }
      ]
    }
  ]
}
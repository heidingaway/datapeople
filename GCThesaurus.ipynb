{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJwrCCFgwmwDYb3jbxTX52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heidingaway/datapeople/blob/main/GCThesaurus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import yaml\n",
        "import re\n",
        "import unicodedata\n",
        "import hashlib"
      ],
      "metadata": {
        "id": "R3eMDEo0AGB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6o7v1_-E_9Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aef379c-3b2e-4d9d-86da-e5cfccf01e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          subject predicate                object\n",
            "0               2-spirited people       Use     Two-spirit people\n",
            "1               2019-nCoV disease       Use  Coronavirus diseases\n",
            "2  2019 novel coronavirus disease       Use  Coronavirus diseases\n",
            "3                 2SLGBTQ+ people       Use      2SLGBTQI+ people\n",
            "4                2SLGBTQI+ people    French    Personne 2ELGBTQI+\n",
            "subject      22146\n",
            "predicate    22146\n",
            "object       22146\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Link to CSV\n",
        "\n",
        "src = \"https://canada.multites.net/cst/EAEAD1E6-7DD2-4997-BE7F-40BFB1CBE8A2/CST20240911.csv\"\n",
        "\n",
        "# Create the DataFrame from all the retrieved records\n",
        "df = pd.read_csv(src)\n",
        "\n",
        "# Add column names\n",
        "df.columns = ['subject', 'predicate', 'object']\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset index with drop=True to avoid creating a new 'index' or 'level_0' column\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Create a new column 'identifier' using the index number\n",
        "df['identifier'] = df.index.astype(str) # Use index as identifier\n",
        "\n",
        "# Define the strings you want to add\n",
        "prefix = \"[[\"  # Prefix without identifier\n",
        "suffix = \"]]\"\n",
        "\n",
        "# Use the apply method with a lambda function to modify the column content\n",
        "# Include identifier in linkedsubject using f-string\n",
        "df['subject'] = df.apply(lambda row: f\"{prefix}{row['identifier']} {row['subject']}{suffix}\", axis=1)\n",
        "\n",
        "# identify long title\n",
        "df = df.rename(columns={'object': 'longTitle'}).sort_values(by='longTitle', ascending=False)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1EbjUqOcuJZ",
        "outputId": "32d3e975-5872-49dd-bee5-0c49aee30ac2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        subject predicate           longTitle identifier\n",
            "1475         [[1475 Art works]]    French         Œuvre d'art       1475\n",
            "10161    [[10161 Human beings]]    French         Être humain      10161\n",
            "19251   [[19251 Sports events]]    French   Événement sportif      19251\n",
            "4635   [[4635 Cultural events]]    French  Événement culturel       4635\n",
            "19712   [[19712 Tax avoidance]]    French    Évitement fiscal      19712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'longTitle' and 'predicate' and aggregate 'linkedsubject' with comma separation\n",
        "grouped_df = cleandf.groupby(['longTitle', 'predicate'])['subject'].apply(lambda x: ', '.join(x)).reset_index()\n",
        "\n",
        "# Before pivoting, reset the index and make \"identifier\" a column instead of the index.\n",
        "pivoted_df = cleandf.pivot_table(\n",
        "    index='longTitle',\n",
        "    columns='predicate',\n",
        "    values='subject',\n",
        "    aggfunc=lambda x: ', '.join(x.dropna().astype(str)) # Changed aggfunc to join values\n",
        ")\n",
        "\n",
        "# Reset index to make 'longTitle' a column again\n",
        "pivoted_df = pivoted_df.reset_index()\n",
        "\n",
        "# Function to remove accents and special characters from a string\n",
        "def clean_title(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii') # Remove accents\n",
        "    text = re.sub(r\"[^a-zA-Z0-9 -]\", \"\", text)  # Remove special characters except spaces and dashes\n",
        "    text = text[:50]  # Truncate to 50 characters if longer\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to the 'title' column\n",
        "pivoted_df['title'] = pivoted_df['longTitle'].apply(clean_title)\n",
        "\n",
        "for column in pivoted_df.columns:\n",
        "    if column not in ['title', 'longTitle']:\n",
        "        pivoted_df[column] = pivoted_df[column].str.replace(\"], \", \"\\n- \", regex=False)\n",
        "\n",
        "print(pivoted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "kdrT1pwue4f_",
        "outputId": "0f17a76b-6b56-4b6f-a8c5-22f1acd1efc3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'predicate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f80912760fab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Group by 'longTitle' and 'predicate' and aggregate 'linkedsubject' with comma separation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrouped_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleandf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longTitle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Before pivoting, reset the index and make \"identifier\" a column instead of the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m pivoted_df = cleandf.pivot_table(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9183\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   9184\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9185\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predicate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"csv_files\"\n",
        "i = 1\n",
        "while os.path.exists(output_dir):\n",
        "    output_dir = f\"csv_files_{i}\"\n",
        "    i += 1\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "# Iterate through each group (title) and export to CSV\n",
        "for title, group_data in pivoted_df.groupby('title'):\n",
        "    file_name = f\"{title}.csv\"  #\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "    group_data.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"CSV files exported to: {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TjdNFdce9iQ",
        "outputId": "396b3785-27f0-46ee-8105-3cbb4f978519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files exported to: csv_files_6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for Markdown files with a unique name\n",
        "dir_name = \"markdown_files\"\n",
        "i = 1\n",
        "while os.path.exists(dir_name):\n",
        "    dir_name = f\"markdown_files_{i}\"\n",
        "    i += 1\n",
        "os.makedirs(dir_name)\n",
        "\n",
        "# Function to create markdown content with bullet points\n",
        "def create_markdown_content(row):\n",
        "    markdown_content = f\"# {row['title']}  \\n\\n\"\n",
        "    for column in pivoted_df.columns:\n",
        "        if column not in ['title', 'longTitle'] and pd.notna(row[column]) and row[column] != '':\n",
        "            markdown_content += f\"{column}\\n\\n\"  # Heading for the section\n",
        "            markdown_content += f\"- {row[column]}  \\n\\n\"  # Add the bulleted content\n",
        "    return markdown_content\n",
        "\n",
        "# Create the markdown files\n",
        "def create_markdown_file(row):  # Define a function to create individual files\n",
        "    file_name = os.path.join(dir_name, f\"{row['title']}.md\")\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(create_markdown_content(row))\n",
        "\n",
        "pivoted_df.apply(create_markdown_file, axis=1)  # Apply to pivoted_df\n",
        "\n",
        "print(f\"Markdown files created successfully in directory: {dir_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pewv8_KkqoQ",
        "outputId": "9c6f7ba3-6ba5-4ce5-cfdf-d25a17d2d6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markdown files created successfully in directory: markdown_files_36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file of the markdown directory\n",
        "def zip_directory(directory_path, zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "        for root, _, files in os.walk(directory_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, directory_path)\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "# Zip the 'markdown_files' directory\n",
        "zip_directory(dir_name, 'markdown_files.zip')\n",
        "\n",
        "print(f\"Markdown files zipped to: markdown_files.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUiOPOWInkWU",
        "outputId": "d8f8d2cd-0f5f-493a-9d9d-8af8716f1ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markdown files zipped to: markdown_files.zip\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy5KaQPRd8DW4AZ8zS74uj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heidingaway/datapeople/blob/main/opengov_country.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ckanapi"
      ],
      "metadata": {
        "id": "6CJUd9i2_xEg",
        "outputId": "4393e050-5bdf-4a22-8c14-786846bcd2db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ckanapi in /usr/local/lib/python3.10/dist-packages (4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ckanapi) (75.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from ckanapi) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ckanapi) (2.32.3)\n",
            "Requirement already satisfied: six<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from ckanapi) (1.17.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from ckanapi) (3.19.3)\n",
            "Requirement already satisfied: python-slugify>=1.0 in /usr/local/lib/python3.10/dist-packages (from ckanapi) (8.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify>=1.0->ckanapi) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ckanapi import RemoteCKAN\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import yaml\n",
        "import re\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "4_uW1oXVd80a"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access resource data via a web API\n",
        "rc = RemoteCKAN('https://open.canada.ca/data/en/')\n",
        "APIID = \"bdb33e8c-53ef-4bae-9493-35f343191c02\"\n",
        "\n",
        "# Initialize an empty list to store all records\n",
        "all_records = []\n",
        "\n",
        "# Set the initial offset and desired limit\n",
        "offset = 0\n",
        "limit = 100  # Or any desired number of records per request\n",
        "\n",
        "while True:\n",
        "    result = rc.action.datastore_search(\n",
        "        resource_id=APIID,\n",
        "        limit=limit,\n",
        "        offset=offset,\n",
        "    )\n",
        "\n",
        "    # Add the retrieved records to the list\n",
        "    all_records.extend(result['records'])\n",
        "\n",
        "    # If the number of records returned is less than the limit,\n",
        "    # it means we've reached the end\n",
        "    if len(result['records']) < limit:\n",
        "        break\n",
        "\n",
        "    # Increment the offset for the next request\n",
        "    offset += limit\n",
        "\n",
        "# Create the DataFrame from all the retrieved records\n",
        "df = pd.DataFrame(all_records)\n",
        "\n",
        "# Add a new 'title' column using the content of 'GC_NM_AB_EN'\n",
        "df['title'] = df['GC_NM_AB_EN']\n",
        "\n",
        "# Remove French accent characters from the 'title' column\n",
        "df['title'] = df['title'].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('ascii'))\n",
        "\n",
        "print(df.count())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zizKBJAMgb5G",
        "outputId": "d514d72c-8a07-4b64-eed4-47d483ff76ee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_id                380\n",
            "GC_HIST_ID         380\n",
            "GC_ID              380\n",
            "GC_NM_OFF_EN       380\n",
            "GC_NM_OFF_FR       380\n",
            "GC_NM_AB_EN        380\n",
            "GC_NM_AB_FR        380\n",
            "STAT_CD            380\n",
            "STAT_DESC_EN       380\n",
            "STAT_DESC_FR       380\n",
            "TYPE_CD            380\n",
            "TYPE_DESC_EN       380\n",
            "TYPE_DESC_FR       380\n",
            "RECENT_IND         380\n",
            "EFF_DT             380\n",
            "EFF_FN_DT          380\n",
            "OBSERVATIONS_EN    380\n",
            "OBSERVATIONS_FR    380\n",
            "GC_PAR_ID            6\n",
            "GC_JUR_ID           53\n",
            "ISO_ALPHA_2_CD     367\n",
            "ISO_ALPHA_3_CD     368\n",
            "UN_ONU_CD          363\n",
            "MODIF_DT           380\n",
            "title              380\n",
            "dtype: int64\n",
            "   _id GC_HIST_ID  GC_ID                                  GC_NM_OFF_EN  \\\n",
            "0    1    1000110  10001                          the Republic of Fiji   \n",
            "1    2    1000210  10002  South Georgia and the South Sandwich Islands   \n",
            "2    3    1000310  10003                the People’s Republic of China   \n",
            "3    4    1000410  10004                      the Republic of Slovenia   \n",
            "4    5    1000508  10005                    Gilbert and Ellice Islands   \n",
            "\n",
            "                                 GC_NM_OFF_FR  \\\n",
            "0                     la République des Fidji   \n",
            "1  Géorgie du Sud-et-les Îles Sandwich du Sud   \n",
            "2            la République populaire de Chine   \n",
            "3                   la République de Slovénie   \n",
            "4                  les îles Gilbert et Ellice   \n",
            "\n",
            "                                    GC_NM_AB_EN  \\\n",
            "0                                          Fiji   \n",
            "1  South Georgia and the South Sandwich Islands   \n",
            "2                                         China   \n",
            "3                                      Slovenia   \n",
            "4                    Gilbert and Ellice Islands   \n",
            "\n",
            "                                  GC_NM_AB_FR STAT_CD STAT_DESC_EN  \\\n",
            "0                                       Fidji       1       ACTIVE   \n",
            "1  Géorgie du Sud-et-les Îles Sandwich du Sud       1       ACTIVE   \n",
            "2                                       Chine       1       ACTIVE   \n",
            "3                                    Slovénie       1       ACTIVE   \n",
            "4                      îles Gilbert et Ellice       2     INACTIVE   \n",
            "\n",
            "  STAT_DESC_FR  ...            EFF_FN_DT OBSERVATIONS_EN OBSERVATIONS_FR  \\\n",
            "0       ACTIVE  ...  2100-01-01T00:00:00            NULL            NULL   \n",
            "1       ACTIVE  ...  2100-01-01T00:00:00            NULL            NULL   \n",
            "2       ACTIVE  ...  2100-01-01T00:00:00            NULL            NULL   \n",
            "3       ACTIVE  ...  2100-01-01T00:00:00            NULL            NULL   \n",
            "4     INACTIVE  ...  1975-12-31T00:00:00            NULL            NULL   \n",
            "\n",
            "  GC_PAR_ID GC_JUR_ID ISO_ALPHA_2_CD ISO_ALPHA_3_CD UN_ONU_CD  \\\n",
            "0      None      None             FJ            FJI       242   \n",
            "1     10183     10135             GS            SGS       239   \n",
            "2      None      None             CN            CHN       156   \n",
            "3      None      None             SI            SVN       705   \n",
            "4      None      None             KI            KIR       296   \n",
            "\n",
            "              MODIF_DT                                         title  \n",
            "0  2023-11-28T00:00:00                                          Fiji  \n",
            "1  2023-11-28T00:00:00  South Georgia and the South Sandwich Islands  \n",
            "2  2023-11-28T00:00:00                                         China  \n",
            "3  2023-11-28T00:00:00                                      Slovenia  \n",
            "4  2023-11-28T00:00:00                    Gilbert and Ellice Islands  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = df[df['STAT_CD'] == \"1\"]\n",
        "clean_output = output[['GC_NM_OFF_EN', 'GC_NM_OFF_FR', 'GC_ID', 'UN_ONU_CD', 'ISO_ALPHA_2_CD','GC_NM_AB_FR', 'GC_NM_AB_EN','MODIF_DT','EFF_DT']].rename(\n",
        "    columns={\n",
        "        'GC_NM_OFF_EN': 'title',\n",
        "        'GC_ID': 'id',\n",
        "        'UN_ONU_CD': 'cd_un',\n",
        "        'ISO_ALPHA_2_CD': 'cd_iso2',\n",
        "        'GC_NM_OFF_FR': 'french',\n",
        "        'GC_NM_AB_EN':'aliases',\n",
        "         'GC_NM_AB_FR':'aliases_fr',\n",
        "        'MODIF_DT':'modified',\n",
        "        'EFF_DT':'effectiveDate'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Create a new column 'identifier' with the specified starting value\n",
        "alias_start = 2025010312471\n",
        "clean_output['identifier'] = range(alias_start, alias_start + len(clean_output))\n",
        "\n",
        "\n",
        "# Convert to datetime if necessary\n",
        "clean_output['modified'] = pd.to_datetime(clean_output['modified'])\n",
        "clean_output['effectiveDate'] = pd.to_datetime(clean_output['effectiveDate'])\n",
        "\n",
        "# Format the columns\n",
        "clean_output['modified'] = clean_output['modified'].dt.strftime('%Y-%m-%d')\n",
        "clean_output['effectiveDate'] = clean_output['effectiveDate'].dt.strftime('%Y-%m-%d')\n",
        "clean_output[\"identifier\"] = clean_output[\"identifier\"].apply(lambda x: f\"\\\"{x}\\\"\" if pd.notna(x) else x)\n",
        "clean_output[\"aliases\"] = clean_output[\"aliases\"].apply(lambda x: f\"\\\"{x}\\\"\" if pd.notna(x) else x)\n",
        "clean_output[\"aliases_fr\"] = clean_output[\"aliases_fr\"].apply(lambda x: f\"\\\"{x}\\\"\" if pd.notna(x) else x)\n",
        "clean_output[\"french\"] = clean_output[\"french\"].apply(lambda x: f\"\\\"{x}\\\"\" if pd.notna(x) else x)\n",
        "\n",
        "# Combine 'aliases', 'aliases_fr', and 'french' into a new column 'aliases_combined'\n",
        "clean_output['aliases_combined'] =  clean_output['identifier'].astype(str) + ', '+clean_output['aliases'].astype(str) + ', ' + clean_output['aliases_fr'].astype(str) + ', ' + clean_output['french'].astype(str)\n",
        "clean_output = clean_output.drop(columns=['aliases', 'aliases_fr', 'identifier'])\n",
        "clean_output = clean_output.rename(columns={'aliases_combined': 'aliases'})\n",
        "\n",
        "clean_output[\"aliases\"] = clean_output[\"aliases\"].apply(lambda x: f\"[{x}]\" if pd.notna(x) else x)\n",
        "\n",
        "\n",
        "print(clean_output.head())\n",
        "print(clean_output.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4kgMu_f1ww8",
        "outputId": "8b33b542-4278-440f-d03e-3d317c0e8c9d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title  \\\n",
            "0                          the Republic of Fiji   \n",
            "1  South Georgia and the South Sandwich Islands   \n",
            "2                the People’s Republic of China   \n",
            "3                      the Republic of Slovenia   \n",
            "6                      the Republic of Kiribati   \n",
            "\n",
            "                                         french     id cd_un cd_iso2  \\\n",
            "0                     \"la République des Fidji\"  10001   242      FJ   \n",
            "1  \"Géorgie du Sud-et-les Îles Sandwich du Sud\"  10002   239      GS   \n",
            "2            \"la République populaire de Chine\"  10003   156      CN   \n",
            "3                   \"la République de Slovénie\"  10004   705      SI   \n",
            "6                   \"la République de Kiribati\"  10005   296      KI   \n",
            "\n",
            "     modified effectiveDate                                            aliases  \n",
            "0  2023-11-28    1970-01-01  [\"2025010312471\", \"Fiji\", \"Fidji\", \"la Républi...  \n",
            "1  2023-11-28    1993-01-01  [\"2025010312472\", \"South Georgia and the South...  \n",
            "2  2023-11-28    1949-01-01  [\"2025010312473\", \"China\", \"Chine\", \"la Républ...  \n",
            "3  2023-11-28    1991-01-01  [\"2025010312474\", \"Slovenia\", \"Slovénie\", \"la ...  \n",
            "6  2023-11-28    1979-01-01  [\"2025010312475\", \"Kiribati\", \"Kiribati\", \"la ...  \n",
            "title            253\n",
            "french           253\n",
            "id               253\n",
            "cd_un            248\n",
            "cd_iso2          252\n",
            "modified         253\n",
            "effectiveDate    253\n",
            "aliases          253\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a new directory for Markdown files with a unique name\n",
        "dir_name = \"markdown_files\"\n",
        "i = 1\n",
        "while os.path.exists(dir_name):\n",
        "    dir_name = f\"markdown_files_{i}\"\n",
        "    i += 1\n",
        "os.makedirs(dir_name)\n",
        "\n",
        "# Function to create markdown content with bullet points\n",
        "def create_markdown_content(row):\n",
        "    markdown_content = f\"---\\ntitle: {row['title']}\\ntags: [place/country, gac]\\ntype: \\\"[[Country]]\\\"\\n\"  # Changed 'type' to 'title'\n",
        "    for column in clean_output.columns:  # Changed grouped_df to clean_output\n",
        "        if column not in ['title']:  # Changed columns to exclude\n",
        "            value = row[column]\n",
        "            # Check if value is a Series and handle it appropriately\n",
        "            if isinstance(value, pd.Series):\n",
        "                # Use any() to check if any value in the Series is not NA and not empty string\n",
        "                if value.notna().any() and value.astype(str).str.strip().ne('').any():\n",
        "                    markdown_content += f\"{column}: {','.join(value.astype(str).tolist())}\\n\"\n",
        "            # If not a Series, use pd.notna as before\n",
        "            elif pd.notna(value) and value != '':\n",
        "                markdown_content += f\"{column}: {value}\\n\"\n",
        "    markdown_content += \"---\"\n",
        "    return markdown_content\n",
        "\n",
        "def create_markdown_file(row):\n",
        "    file_name = os.path.join(dir_name, f\"{row['title']}.md\")  # Changed 'type' to 'title'\n",
        "    with open(file_name, \"w\") as f:\n",
        "        markdown_content = create_markdown_content(row)\n",
        "        f.write(markdown_content)\n",
        "    return alias_start + 1\n",
        "\n",
        "# Apply with alias_start and accumulate the updated alias_start\n",
        "alias_start = clean_output.apply(lambda row: create_markdown_file(row), axis=1).iloc[-1]\n",
        "\n",
        "print(f\"Markdown files created successfully in directory: {dir_name}\")"
      ],
      "metadata": {
        "id": "8E_bsriOiaqe",
        "outputId": "1eef8571-3263-4d63-b043-9650e228df6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markdown files created successfully in directory: markdown_files_7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Zip the output folder\n",
        "zip_file_name = f\"{dir_name}.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
        "    for root, _, files in os.walk(dir_name):  # change ufolder_name to dir_name\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), dir_name))  # change ufolder_name to dir_name\n",
        "\n",
        "print(f\"Output files zipped to: {zip_file_name}\")"
      ],
      "metadata": {
        "id": "Bgxqy4jtM5ka",
        "outputId": "7e0d3c26-5009-4e06-d7d0-e0b48329e891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output files zipped to: markdown_files_7.zip\n"
          ]
        }
      ]
    }
  ]
}